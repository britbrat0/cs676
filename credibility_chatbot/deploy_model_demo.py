# -*- coding: utf-8 -*-
"""deploy_model_demo

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MvpX2PbXH-HNZCjzdyNRXSZ1whhgk2yu

# Credibility Scoring Chatbot Project

This notebook demonstrates the development and deployment of a hybrid credibility scoring model for URLs and web content.  
It includes:

1. **Hybrid credibility model**: Combines rule-based signals (content length, domain authority, citation patterns) with ML predictions.  
2. **Streamlit chatbot integration**: Answers questions using GPT models, incorporates web search results, and provides credibility scores.  
3. **Deployment demonstration**: Shows how to deploy the trained ML model artifact (`credibility_model.pkl`) to Hugging Face Hub and use it reproducibly.  

The workflow is fully reproducible and demonstrates production-ready capabilities.

## Demonstrating Model Deployment

This section shows how the trained credibility scoring model (`credibility_model.pkl`) can be deployed, shared, and used reproducibly:

1. **Deployment to Hugging Face Hub:**  
   - The trained model artifact is uploaded to a Hugging Face repository.  
   - Allows anyone to download and use the model without needing the original notebook or local files.

2. **Downloading the Model:**  
   - Using the `huggingface_hub` library, the model can be programmatically downloaded from the Hub.  
   - Ensures portability across environments.

3. **Loading and Using the Model:**  
   - The `.pkl` file is loaded using Pythonâ€™s `pickle` module.  
   - A sample feature vector is used to demonstrate a prediction, verifying functionality.

4. **Environment Security:**  
   - The Hugging Face token is loaded from an environment variable (`HF_TOKEN`) to avoid exposing secrets.  
   - This ensures safe and reproducible usage.

This workflow demonstrates that the model is **deployment-ready**, reproducible, and can be integrated into downstream applications like the Streamlit chatbot.
"""

# -----------------------------
# Hugging Face Model Deployment Demo
# -----------------------------
# This cell downloads the trained model from Hugging Face Hub,
# loads it in Python, and performs a test prediction.
# -----------------------------

# Install Hugging Face Hub if needed
!pip install huggingface_hub --quiet

from huggingface_hub import hf_hub_download
import pickle
import os

# -----------------------------
# Hugging Face repository info
# -----------------------------
repo_id = "your-username/credibility-model"  # Replace with your HF repo
hf_token = os.getenv("HF_TOKEN")  # safer than hardcoding your token

if not hf_token:
    print("Set your HF_TOKEN environment variable before running this cell.")
else:
    # -----------------------------
    # Download the model from HF Hub
    # -----------------------------
    model_path = hf_hub_download(
        repo_id=repo_id,
        filename="credibility_model.pkl",
        token=hf_token
    )

    # -----------------------------
    # Load the model
    # -----------------------------
    with open(model_path, "rb") as f:
        credibility_model = pickle.load(f)

    print("Model loaded successfully!")

    # -----------------------------
    # Test a sample prediction
    # -----------------------------
    sample_features = [[1000, 15]]  # Example: content length, domain length
    pred_score = credibility_model.predict(sample_features)[0]
    print("Predicted credibility score:", pred_score)

"""### Integration with Chatbot

The downloaded model can now be used in the Streamlit chatbot to score URLs dynamically.  
For example, the chatbot can:

- Download the latest model from Hugging Face at startup.
- Use `assess_url_credibility()` to compute credibility scores for URLs or web results.
- Provide users with both an answer and the credibility assessment.

This ensures that the chatbot always uses a reproducible, deployment-ready model.

"""

